# MTLNet: Multi-task Learning with Limited Data for Source-free Cross-domain Few-shot Semantic Segmentation

## Introduction

**Abstract**  
Cross-domain few-shot semantic segmentation (CD-FSS) aims to achieve efficient image segmentation within a target domain using limited annotated data. Existing methods often require access to source data during training. However, with growing concerns over data privacy and the need to reduce data transfer and training costs, developing a CD-FSS solution that does not require access to source data is necessary. 

To address this issue, this paper proposes a multi-task learning-based source-free cross-domain few-shot semantic segmentation method (MTLNet). This method optimizes and fine-tunes the model using a minimal amount of target domain data without accessing source domain data, thereby improving segmentation performance.  

Key contributions include:
- **Hierarchical Mask module**: Combines contrastive learning and supervised learning to prevent model overfitting and enhance generalization.
- **Multi-task loss function**: Helps capture general patterns and reduces overfitting to a single task, improving robustness in new data.
- **Triplet Contextual Alignment strategy**: Manages dependencies between tasks, optimizing performance in semantic segmentation.

Experimental results demonstrate that MTLNet significantly outperforms the CD-FSS baseline, showcasing the potential of multi-task learning when trained on extremely small amounts of target domain data.

## Datasets

The following datasets are used for evaluation in CD-FSS:

### Source Domain:
- **PASCAL VOC2012**  
  Download the PASCAL VOC2012 devkit (train/val data):  
  ```bash
  wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
